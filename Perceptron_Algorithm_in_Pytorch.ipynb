{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Apoak/307take2/blob/main/Perceptron_Algorithm_in_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPpqud-TRJSJ"
      },
      "source": [
        "### Lab 2.2: Perceptron Algorithm in PyTorch\n",
        "\n",
        "In this lab you will again implement the perceptron algorithm, but this time using PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cC1uOd6RJSL"
      },
      "outputs": [],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXNbI3mwRJSL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbxWJjd2RJSM"
      },
      "source": [
        "PyTorch is very similar to NumPy in its basic functionality.  In PyTorch arrays are called tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMi186mpRJSM"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor(5)\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZkr7q58RJSM"
      },
      "outputs": [],
      "source": [
        "b = torch.tensor(6)\n",
        "a+b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lgJKC12RJSN"
      },
      "outputs": [],
      "source": [
        "c = torch.zeros(3,5).float()\n",
        "c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYgm7hnkRJSN"
      },
      "source": [
        "*A note on broadcasting:* You may have noticed in the previous lab that NumPy is particular about the sizes of the arrays in operations; PyTorch is the same way.\n",
        "\n",
        "For example, if `A` has shape `(10,5)` and `b` has shape `(10,)`, then we can't compute `A*b`.  It wants the *last* dimensions to match, not the first ones.  So you would need to do either `A.T*b`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qat1VaZFRJSN"
      },
      "outputs": [],
      "source": [
        "A = np.random.normal(size=(10,5))\n",
        "b = np.ones(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwucilnCRJSO"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    A*b\n",
        "except ValueError as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mif4DunfRJSO"
      },
      "outputs": [],
      "source": [
        "A.T*b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ts97P087RJSP"
      },
      "source": [
        "An alternative is to introduce an extra dimension of size one to $b$.  However, note that this produces the transposed result from before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddASy85uRJSP"
      },
      "outputs": [],
      "source": [
        "A*b[:,None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uENS5aJRJSP"
      },
      "outputs": [],
      "source": [
        "A*np.expand_dims(b,-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7aQdxXARJSP"
      },
      "source": [
        "In general, carefully check the sizes of all arrays in your code!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn palmerpenguins mlxtend"
      ],
      "metadata": {
        "id": "EM711QGzRk2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvySmGaJRJSP"
      },
      "outputs": [],
      "source": [
        "from palmerpenguins import load_penguins\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFqPcKxTRJSQ"
      },
      "source": [
        "Here we loading and format the Palmer penguins dataset for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eGsnTL2RJSQ"
      },
      "outputs": [],
      "source": [
        "df = load_penguins()\n",
        "\n",
        "# drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# tricky code to randomly shuffle the rows\n",
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# select only two specices\n",
        "df = df[(df['species']=='Adelie')|(df['species']=='Chinstrap')]\n",
        "\n",
        "# get two features\n",
        "X = df[['flipper_length_mm','bill_length_mm']].values\n",
        "\n",
        "# convert speces labels to -1 and 1\n",
        "y = df['species'].map({'Adelie':-1,'Chinstrap':1}).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcTDAfroRJSQ"
      },
      "source": [
        "To make the learning algorithm work more smoothly, we we will subtract the mean of each feature.\n",
        "\n",
        "Here `np.mean` calculates a mean, and `axis=0` tells NumPy to calculate the mean over the rows (calculate the mean of each column)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0OHLQ_gRJSQ"
      },
      "outputs": [],
      "source": [
        "X -= np.mean(X,axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbb_pHpnRJSQ"
      },
      "source": [
        "Now we will convert our `X` and `y` arrays to torch Tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "82HvClAdRJSQ"
      },
      "outputs": [],
      "source": [
        "X = torch.tensor(X).float()\n",
        "y = torch.tensor(y).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJxiU_tuRJSQ"
      },
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgS6TyoGRJSQ"
      },
      "source": [
        "### Exercises\n",
        "\n",
        "Your task is to again complete this class for the perceptron, with two changes from last time:\n",
        "- the implementation should use PyTorch tensors, not NumPy arrays;\n",
        "- `train_step` now accepts the entire dataset as input and should calculate the average gradient over all examples, rather than updating the weights one data point at a time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c7eTDYeRJSQ"
      },
      "outputs": [],
      "source": [
        "class Perceptron:\n",
        "    def __init__(self,lr=1e-3):\n",
        "        # store the learning rate\n",
        "        self.lr = lr\n",
        "\n",
        "        # initialize the weights to small, normally-distributed values\n",
        "        self.w = torch.normal(mean=0, std=0.01, size=(2,))\n",
        "\n",
        "        # initialize the bias to zero\n",
        "        self.b = torch.zeros(1)\n",
        "\n",
        "    def train_step(self,X:torch.Tensor,y:torch.Tensor) -> None:\n",
        "        \"\"\" Apply the first update rule shown in lecture.\n",
        "            Arguments:\n",
        "             x: data matrix of shape (N,3)\n",
        "             y: labels of shape (N,)\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        z = X @ self.w.T + self.b\n",
        "        # print(X.shape)\n",
        "        # print(z.shape)\n",
        "        # print(y.shape)\n",
        "        gradient_sum = 0\n",
        "        for n in range(X.shape[0]):\n",
        "          for m in range(X.shape[1]):\n",
        "            gradient_sum += (z - y) * X.T\n",
        "        ave_grad = torch.mean(gradient_sum)\n",
        "\n",
        "        # print(ave_grad.shape)\n",
        "        self.w.T - self.lr * ave_grad\n",
        "        # print(self.w)\n",
        "\n",
        "    def predict(self,X:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Calculate model prediction for all data points.\n",
        "            Arguments:\n",
        "             X: data matrix of shape (N,3)\n",
        "            Returns:\n",
        "             Predicted labels (-1 or 1) of shape (N,)\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        z = X @ self.w + self.b\n",
        "        return torch.where(z>0,1,-1)\n",
        "\n",
        "    def score(self,X:torch.Tensor,y:torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" Calculate model accuracy\n",
        "            Arguments:\n",
        "             X: data matrix of shape (N,3)\n",
        "             y: labels of shape (N,)\n",
        "            Returns:\n",
        "             Accuracy score\n",
        "        \"\"\"\n",
        "        # WRITE CODE HERE\n",
        "        pred = self.predict(X)\n",
        "        return torch.mean((pred == y).float())\n",
        "\n",
        "# lr = 1e-3\n",
        "# model = Perceptron(lr)\n",
        "# model.train_step(X,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvJO0FSxRJSR"
      },
      "source": [
        "Run the following code to train the model and print out the accuracy at each step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pUMTD98RJSR"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "epochs = 100\n",
        "model = Perceptron(lr)\n",
        "for i in range(epochs):\n",
        "    model.train_step(X,y)\n",
        "    print(f'step {i}: {model.score(X,y)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "QUESTION: The score values are drastically different each time, this seems like very abnormal behavior."
      ],
      "metadata": {
        "id": "CzoUStH4j1XH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h67ofbpKRJSR"
      },
      "source": [
        "Run the training multiple times.  Is the training the same each time, or does it vary?  Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3Q7tzWeRJSR"
      },
      "source": [
        "Play with the learning rate and number of epochs to find the best setting."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}